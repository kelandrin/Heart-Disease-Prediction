{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "# Helper libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "# TensorFlow and tf.keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get values to be between 0 and 1\n",
    "\n",
    "def feature_normalize(dataset):\n",
    "    return(dataset-dataset.min())/(dataset.max()-dataset.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/a/42523230\n",
    "def one_hot(df, cols):\n",
    "    \"\"\"\n",
    "    @param df pandas DataFrame\n",
    "    @param cols a list of columns to encode \n",
    "    @return a DataFrame with one-hot encoding\n",
    "    \"\"\"\n",
    "    for each in cols:\n",
    "        dummies = pd.get_dummies(df[each], prefix=each, drop_first=False)\n",
    "        del df[each]\n",
    "        df = pd.concat([df, dummies], axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_processing(df):\n",
    "    \n",
    "    #rename a col \n",
    "    df.rename(columns = {\"Oldpeak \":\"Oldpeak\"}, inplace = True)\n",
    "\n",
    "    #replace numeric values with strs\n",
    "    df['Heart Disease Labels'] = df['Heart Disease'].astype(str).replace({'1': 'Absence', \"2\":\"Presence\"})\n",
    "    df['Heart Disease'] = df['Heart Disease'].astype(int).replace({1 : 0, 2:1})\n",
    "    \n",
    "    #Age normalization\n",
    "    df[\"Age\"] = feature_normalize(df[\"Age\"])\n",
    "    #Resting Bps normalization\n",
    "    df[\"Trestbps\"] = feature_normalize(df[\"Trestbps\"])\n",
    "    #Cholesterol normalization\n",
    "    df[\"Chol\"] = feature_normalize(df[\"Chol\"])\n",
    "    #Max heartrate normalization\n",
    "    df[\"maxhr\"] = feature_normalize(df[\"maxhr\"])\n",
    "    #Oldpeak normalization\n",
    "    df[\"Oldpeak\"] = feature_normalize(df[\"Oldpeak\"])\n",
    "    \n",
    "    #one_hot categorical vars\n",
    "    df = one_hot(df, df.loc[:, [\"Sex\",\"CP\",\"Fbs\",\"Restecg\",\"Exang\",\"Slope\",\"Ca\",\"Thal\"]].columns)\n",
    "    \n",
    "    #move heart disease column to the end\n",
    "    cols = list(df.columns.values) #Make a list of all of the columns in the df\n",
    "    cols.pop(cols.index('Heart Disease')) #pop heart disease\n",
    "    cols.pop(cols.index('Heart Disease Labels')) #pop heart disease labels\n",
    "    df = df[cols+['Heart Disease',\"Heart Disease Labels\"]] #Create new dataframe with columns in the order you want\n",
    "    \n",
    "    return df  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Heart Data.csv\", skiprows = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Trestbps</th>\n",
       "      <th>Chol</th>\n",
       "      <th>maxhr</th>\n",
       "      <th>Oldpeak</th>\n",
       "      <th>Sex_0</th>\n",
       "      <th>Sex_1</th>\n",
       "      <th>CP_1</th>\n",
       "      <th>CP_2</th>\n",
       "      <th>CP_3</th>\n",
       "      <th>...</th>\n",
       "      <th>Slope_3</th>\n",
       "      <th>Ca_0</th>\n",
       "      <th>Ca_1</th>\n",
       "      <th>Ca_2</th>\n",
       "      <th>Ca_3</th>\n",
       "      <th>Thal_3</th>\n",
       "      <th>Thal_6</th>\n",
       "      <th>Thal_7</th>\n",
       "      <th>Heart Disease</th>\n",
       "      <th>Heart Disease Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.854167</td>\n",
       "      <td>0.339623</td>\n",
       "      <td>0.447489</td>\n",
       "      <td>0.290076</td>\n",
       "      <td>0.387097</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Presence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.198113</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.679389</td>\n",
       "      <td>0.258065</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Absence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.283019</td>\n",
       "      <td>0.308219</td>\n",
       "      <td>0.534351</td>\n",
       "      <td>0.048387</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Presence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.729167</td>\n",
       "      <td>0.320755</td>\n",
       "      <td>0.312785</td>\n",
       "      <td>0.259542</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Absence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.245283</td>\n",
       "      <td>0.326484</td>\n",
       "      <td>0.381679</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Absence</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Age  Trestbps      Chol     maxhr   Oldpeak  Sex_0  Sex_1  CP_1  CP_2  \\\n",
       "0  0.854167  0.339623  0.447489  0.290076  0.387097      0      1     0     0   \n",
       "1  0.791667  0.198113  1.000000  0.679389  0.258065      1      0     0     0   \n",
       "2  0.583333  0.283019  0.308219  0.534351  0.048387      0      1     0     1   \n",
       "3  0.729167  0.320755  0.312785  0.259542  0.032258      0      1     0     0   \n",
       "4  0.937500  0.245283  0.326484  0.381679  0.032258      1      0     0     1   \n",
       "\n",
       "   CP_3  ...  Slope_3  Ca_0  Ca_1  Ca_2  Ca_3  Thal_3  Thal_6  Thal_7  \\\n",
       "0     0  ...        0     0     0     0     1       1       0       0   \n",
       "1     1  ...        0     1     0     0     0       0       0       1   \n",
       "2     0  ...        0     1     0     0     0       0       0       1   \n",
       "3     0  ...        0     0     1     0     0       0       0       1   \n",
       "4     0  ...        0     0     1     0     0       1       0       0   \n",
       "\n",
       "   Heart Disease  Heart Disease Labels  \n",
       "0              1              Presence  \n",
       "1              0               Absence  \n",
       "2              1              Presence  \n",
       "3              0               Absence  \n",
       "4              0               Absence  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Process dataframe using one_hot and normalization\n",
    "df = pre_processing(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.8541666666666666 0.33962264150943394 0.4474885844748858 ... 0 1\n",
      "  'Presence']\n",
      " [0.7916666666666666 0.19811320754716982 1.0 ... 1 0 'Absence']\n",
      " [0.5833333333333334 0.2830188679245283 0.3082191780821918 ... 1 1\n",
      "  'Presence']\n",
      " ...\n",
      " [0.5625 0.4339622641509434 0.3835616438356164 ... 0 0 'Absence']\n",
      " [0.5833333333333334 0.4339622641509434 0.1506849315068493 ... 0 0\n",
      "  'Absence']\n",
      " [0.7916666666666666 0.6226415094339622 0.365296803652968 ... 0 1\n",
      "  'Presence']]\n"
     ]
    }
   ],
   "source": [
    "dfnparray = df.values\n",
    "print(dfnparray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df.sample(frac=0.7, random_state=138)\n",
    "test = df.drop(train.index)\n",
    "\n",
    "#creating the array of values\n",
    "dfnparray_train = train.values\n",
    "dfnparray_test = test.values\n",
    "\n",
    "#creating train label and train set\n",
    "train   = dfnparray_train[:, :-2]\n",
    "train_label = dfnparray_train[:, [-2]]\n",
    "\n",
    "#creating test label and test set\n",
    "test   = dfnparray_test[:, :-2]\n",
    "test_label = dfnparray_test[:, [-2]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.astype('float32')\n",
    "train_label = train_label.astype('float32')\n",
    "test = test.astype('float32')\n",
    "test_label = test_label.astype('float32')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Copyright 2019 The TensorFlow Authors. All Rights Reserved.\\n#\\n# Licensed under the Apache License, Version 2.0 (the \"License\");\\n# you may not use this file except in compliance with the License.\\n# You may obtain a copy of the License at\\n#\\n#     http://www.apache.org/licenses/LICENSE-2.0\\n#\\n# Unless required by applicable law or agreed to in writing, software\\n# distributed under the License is distributed on an \"AS IS\" BASIS,\\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\\n# See the License for the specific language governing permissions and\\n# limitations under the License.\\n# ==============================================================================\\n\"\"\"Self-diagnosis script for TensorBoard.\\n\\nInstructions: Save this script to your local machine, then execute it in\\nthe same environment (virtualenv, Conda, etc.) from which you normally\\nrun TensorBoard. Read the output and follow the directions.\\n\"\"\"\\n\\nfrom __future__ import absolute_import\\nfrom __future__ import division\\nfrom __future__ import print_function\\n\\n# This script may only depend on the Python standard library. It is not\\n# built with Bazel and should not assume any third-party dependencies.\\nimport collections\\nimport errno\\nimport functools\\nimport hashlib\\nimport inspect\\nimport logging\\nimport os\\nimport pipes\\nimport shlex\\nimport socket\\nimport subprocess\\nimport sys\\nimport tempfile\\nimport textwrap\\nimport traceback\\n\\n\\n# A *check* is a function (of no arguments) that performs a diagnostic,\\n# writes log messages, and optionally yields suggestions. Each check\\n# runs in isolation; exceptions will be caught and reported.\\nCHECKS = []\\n\\n\\n# A suggestion to the end user.\\n#   headline (str): A short description, like \"Turn it off and on\\n#     again\". Should be imperative with no trailing punctuation. May\\n#     contain inline Markdown.\\n#   description (str): A full enumeration of the steps that the user\\n#     should take to accept the suggestion. Within this string, prose\\n#     should be formatted with `reflow`. May contain Markdown.\\nSuggestion = collections.namedtuple(\"Suggestion\", (\"headline\", \"description\"))\\n\\n\\ndef check(fn):\\n  \"\"\"Decorator to register a function as a check.\\n\\n  Checks are run in the order in which they are registered.\\n\\n  Args:\\n    fn: A function that takes no arguments and either returns `None` or\\n      returns a generator of `Suggestion`s. (The ability to return\\n      `None` is to work around the awkwardness of defining empty\\n      generator functions in Python.)\\n\\n  Returns:\\n    A wrapped version of `fn` that returns a generator of `Suggestion`s.\\n  \"\"\"\\n  @functools.wraps(fn)\\n  def wrapper():\\n    result = fn()\\n    return iter(()) if result is None else result\\n  CHECKS.append(wrapper)\\n  return wrapper\\n\\n\\ndef reflow(paragraph):\\n  return textwrap.fill(textwrap.dedent(paragraph).strip())\\n\\n\\ndef pip(args):\\n  \"\"\"Invoke command-line Pip with the specified args.\\n\\n  Returns:\\n    A bytestring containing the output of Pip.\\n  \"\"\"\\n  # Suppress the Python 2.7 deprecation warning.\\n  PYTHONWARNINGS_KEY = \"PYTHONWARNINGS\"\\n  old_pythonwarnings = os.environ.get(PYTHONWARNINGS_KEY)\\n  new_pythonwarnings = \"%s%s\" % (\\n      \"ignore:DEPRECATION\",\\n      \",%s\" % old_pythonwarnings if old_pythonwarnings else \"\",\\n  )\\n  command = [sys.executable, \"-m\", \"pip\", \"--disable-pip-version-check\"]\\n  command.extend(args)\\n  try:\\n    os.environ[PYTHONWARNINGS_KEY] = new_pythonwarnings\\n    return subprocess.check_output(command)\\n  finally:\\n    if old_pythonwarnings is None:\\n      del os.environ[PYTHONWARNINGS_KEY]\\n    else:\\n      os.environ[PYTHONWARNINGS_KEY] = old_pythonwarnings\\n\\n\\ndef which(name):\\n  \"\"\"Return the path to a binary, or `None` if it\\'s not on the path.\\n\\n  Returns:\\n    A bytestring.\\n  \"\"\"\\n  binary = \"where\" if os.name == \"nt\" else \"which\"\\n  try:\\n    return subprocess.check_output([binary, name])\\n  except subprocess.CalledProcessError:\\n    return None\\n\\n\\n@check\\ndef autoidentify():\\n  \"\"\"Print the Git hash of this version of `diagnose_tensorboard.py`.\\n\\n  Given this hash, use `git cat-file blob HASH` to recover the relevant\\n  version of the script.\\n  \"\"\"\\n  module = sys.modules[__name__]\\n  try:\\n    source = inspect.getsource(module).encode(\"utf-8\")\\n  except TypeError:\\n    logging.info(\"diagnose_tensorboard.py source unavailable\")\\n  else:\\n    # Git inserts a length-prefix before hashing; cf. `git-hash-object`.\\n    blob = b\"blob %d\\x00%s\" % (len(source), source)\\n    hash = hashlib.sha1(blob).hexdigest()\\n    logging.info(\"diagnose_tensorboard.py version %s\", hash)\\n\\n\\n@check\\ndef general():\\n  logging.info(\"sys.version_info: %s\", sys.version_info)\\n  logging.info(\"os.name: %s\", os.name)\\n  na = type(\"N/A\", (object,), {\"__repr__\": lambda self: \"N/A\"})\\n  logging.info(\"os.uname(): %r\", getattr(os, \"uname\", na)(),)\\n  logging.info(\\n      \"sys.getwindowsversion(): %r\",\\n      getattr(sys, \"getwindowsversion\", na)(),\\n  )\\n\\n\\n@check\\ndef package_management():\\n  conda_meta = os.path.join(sys.prefix, \"conda-meta\")\\n  logging.info(\"has conda-meta: %s\", os.path.exists(conda_meta))\\n  logging.info(\"$VIRTUAL_ENV: %r\", os.environ.get(\"VIRTUAL_ENV\"))\\n\\n\\n@check\\ndef installed_packages():\\n  freeze = pip([\"freeze\", \"--all\"]).decode(\"utf-8\").splitlines()\\n  packages = {line.split(u\"==\")[0]: line for line in freeze}\\n  packages_set = frozenset(packages)\\n\\n  # For each of the following families, expect exactly one package to be\\n  # installed.\\n  expect_unique = [\\n      frozenset([\\n          u\"tensorboard\",\\n          u\"tb-nightly\",\\n          u\"tensorflow-tensorboard\",\\n      ]),\\n      frozenset([\\n          u\"tensorflow\",\\n          u\"tensorflow-gpu\",\\n          u\"tf-nightly\",\\n          u\"tf-nightly-2.0-preview\",\\n          u\"tf-nightly-gpu\",\\n          u\"tf-nightly-gpu-2.0-preview\",\\n      ]),\\n      frozenset([\\n          u\"tensorflow-estimator\",\\n          u\"tensorflow-estimator-2.0-preview\",\\n          u\"tf-estimator-nightly\",\\n      ]),\\n  ]\\n\\n  found_conflict = False\\n  for family in expect_unique:\\n    actual = family & packages_set\\n    for package in actual:\\n      logging.info(\"installed: %s\", packages[package])\\n    if len(actual) == 0:\\n      logging.warning(\"no installation among: %s\", sorted(family))\\n    elif len(actual) > 1:\\n      logging.warning(\"conflicting installations: %s\", sorted(actual))\\n      found_conflict = True\\n\\n  if found_conflict:\\n    preamble = reflow(\\n        \"\"\"\\n        Conflicting package installations found. Depending on the order\\n        of installations and uninstallations, behavior may be undefined.\\n        Please uninstall ALL versions of TensorFlow and TensorBoard,\\n        then reinstall ONLY the desired version of TensorFlow, which\\n        will transitively pull in the proper version of TensorBoard. (If\\n        you use TensorBoard without TensorFlow, just reinstall the\\n        appropriate version of TensorBoard directly.)\\n        \"\"\"\\n    )\\n    packages_to_uninstall = sorted(\\n        frozenset().union(*expect_unique) & packages_set\\n    )\\n    commands = [\\n        \"pip uninstall %s\" % \" \".join(packages_to_uninstall),\\n        \"pip install tensorflow  # or `tensorflow-gpu`, or `tf-nightly`, ...\",\\n    ]\\n    message = \"%s\\n\\nNamely:\\n\\n%s\" % (\\n        preamble,\\n        \"\\n\".join(\"\\t%s\" % c for c in commands),\\n    )\\n    yield Suggestion(\"Fix conflicting installations\", message)\\n\\n\\n@check\\ndef tensorboard_python_version():\\n  from tensorboard import version\\n  logging.info(\"tensorboard.version.VERSION: %r\", version.VERSION)\\n\\n\\n@check\\ndef tensorflow_python_version():\\n  import tensorflow as tf\\n  logging.info(\"tensorflow.__version__: %r\", tf.__version__)\\n  logging.info(\"tensorflow.__git_version__: %r\", tf.__git_version__)\\n\\n\\n@check\\ndef tensorboard_binary_path():\\n  logging.info(\"which tensorboard: %r\", which(\"tensorboard\"))\\n\\n\\n@check\\ndef readable_fqdn():\\n  # May raise `UnicodeDecodeError` for non-ASCII hostnames:\\n  # https://github.com/tensorflow/tensorboard/issues/682\\n  try:\\n    logging.info(\"socket.getfqdn(): %r\", socket.getfqdn())\\n  except UnicodeDecodeError as e:\\n    try:\\n      binary_hostname = subprocess.check_output([\"hostname\"]).strip()\\n    except subprocess.CalledProcessError:\\n      binary_hostname = b\"<unavailable>\"\\n    is_non_ascii = not all(\\n        0x20 <= (ord(c) if not isinstance(c, int) else c) <= 0x7E  # Python 2\\n        for c in binary_hostname\\n    )\\n    if is_non_ascii:\\n      message = reflow(\\n          \"\"\"\\n          Your computer\\'s hostname, %r, contains bytes outside of the\\n          printable ASCII range. Some versions of Python have trouble\\n          working with such names (https://bugs.python.org/issue26227).\\n          Consider changing to a hostname that only contains printable\\n          ASCII bytes.\\n          \"\"\" % (binary_hostname,)\\n      )\\n      yield Suggestion(\"Use an ASCII hostname\", message)\\n    else:\\n      message = reflow(\\n          \"\"\"\\n          Python can\\'t read your computer\\'s hostname, %r. This can occur\\n          if the hostname contains non-ASCII bytes\\n          (https://bugs.python.org/issue26227). Consider changing your\\n          hostname, rebooting your machine, and rerunning this diagnosis\\n          script to see if the problem is resolved.\\n          \"\"\" % (binary_hostname,)\\n      )\\n      yield Suggestion(\"Use a simpler hostname\", message)\\n    raise e\\n\\n\\n@check\\ndef stat_tensorboardinfo():\\n  # We don\\'t use `manager._get_info_dir`, because (a) that requires\\n  # TensorBoard, and (b) that creates the directory if it doesn\\'t exist.\\n  path = os.path.join(tempfile.gettempdir(), \".tensorboard-info\")\\n  logging.info(\"directory: %s\", path)\\n  try:\\n    stat_result = os.stat(path)\\n  except OSError as e:\\n    if e.errno == errno.ENOENT:\\n      # No problem; this is just fine.\\n      logging.info(\".tensorboard-info directory does not exist\")\\n      return\\n    else:\\n      raise\\n  logging.info(\"os.stat(...): %r\", stat_result)\\n  logging.info(\"mode: 0o%o\", stat_result.st_mode)\\n  if stat_result.st_mode & 0o777 != 0o777:\\n    preamble = reflow(\\n        \"\"\"\\n        The \".tensorboard-info\" directory was created by an old version\\n        of TensorBoard, and its permissions are not set correctly; see\\n        issue #2010. Change that directory to be world-accessible (may\\n        require superuser privilege):\\n        \"\"\"\\n    )\\n    # This error should only appear on Unices, so it\\'s okay to use\\n    # Unix-specific utilities and shell syntax.\\n    quote = getattr(shlex, \"quote\", None) or pipes.quote  # Python <3.3\\n    command = \"chmod 777 %s\" % quote(path)\\n    message = \"%s\\n\\n\\t%s\" % (preamble, command)\\n    yield Suggestion(\"Fix permissions on \"%s\"\" % path, message)\\n\\n\\n@check\\ndef source_trees_without_genfiles():\\n  roots = list(sys.path)\\n  if \"\" not in roots:\\n    # Catch problems that would occur in a Python interactive shell\\n    # (where `\"\"` is prepended to `sys.path`) but not when\\n    # `diagnose_tensorboard.py` is run as a standalone script.\\n    roots.insert(0, \"\")\\n\\n  def has_tensorboard(root):\\n    return os.path.isfile(os.path.join(root, \"tensorboard\", \"__init__.py\"))\\n  def has_genfiles(root):\\n    sample_genfile = os.path.join(\"compat\", \"proto\", \"summary_pb2.py\")\\n    return os.path.isfile(os.path.join(root, \"tensorboard\", sample_genfile))\\n  def is_bad(root):\\n    return has_tensorboard(root) and not has_genfiles(root)\\n\\n  tensorboard_roots = [root for root in roots if has_tensorboard(root)]\\n  bad_roots = [root for root in roots if is_bad(root)]\\n\\n  logging.info(\\n      \"tensorboard_roots (%d): %r; bad_roots (%d): %r\",\\n      len(tensorboard_roots),\\n      tensorboard_roots,\\n      len(bad_roots),\\n      bad_roots,\\n  )\\n\\n  if bad_roots:\\n    if bad_roots == [\"\"]:\\n      message = reflow(\\n          \"\"\"\\n          Your current directory contains a `tensorboard` Python package\\n          that does not include generated files. This can happen if your\\n          current directory includes the TensorBoard source tree (e.g.,\\n          you are in the TensorBoard Git repository). Consider changing\\n          to a different directory.\\n          \"\"\"\\n      )\\n    else:\\n      preamble = reflow(\\n          \"\"\"\\n          Your Python path contains a `tensorboard` package that does\\n          not include generated files. This can happen if your current\\n          directory includes the TensorBoard source tree (e.g., you are\\n          in the TensorBoard Git repository). The following directories\\n          from your Python path may be problematic:\\n          \"\"\"\\n      )\\n      roots = []\\n      realpaths_seen = set()\\n      for root in bad_roots:\\n        label = repr(root) if root else \"current directory\"\\n        realpath = os.path.realpath(root)\\n        if realpath in realpaths_seen:\\n          # virtualenvs on Ubuntu install to both `lib` and `local/lib`;\\n          # explicitly call out such duplicates to avoid confusion.\\n          label += \" (duplicate underlying directory)\"\\n        realpaths_seen.add(realpath)\\n        roots.append(label)\\n      message = \"%s\\n\\n%s\" % (preamble, \"\\n\".join(\"  - %s\" % s for s in roots))\\n    yield Suggestion(\"Avoid `tensorboard` packages without genfiles\", message)\\n\\n\\n# Prefer to include this check last, as its output is long.\\n@check\\ndef full_pip_freeze():\\n  logging.info(\"pip freeze --all:\\n%s\", pip([\"freeze\", \"--all\"]).decode(\"utf-8\"))\\n\\n\\ndef set_up_logging():\\n  # Manually install handlers to prevent TensorFlow from stomping the\\n  # default configuration if it\\'s imported:\\n  # https://github.com/tensorflow/tensorflow/issues/28147\\n  logger = logging.getLogger()\\n  logger.setLevel(logging.INFO)\\n  handler = logging.StreamHandler(sys.stdout)\\n  handler.setFormatter(logging.Formatter(\"%(levelname)s: %(message)s\"))\\n  logger.addHandler(handler)\\n\\n\\ndef main():\\n  set_up_logging()\\n\\n  print(\"### Diagnostics\")\\n  print()\\n\\n  print(\"<details>\")\\n  print(\"<summary>Diagnostics output</summary>\")\\n  print()\\n\\n  markdown_code_fence = \"``````\"  # seems likely to be sufficient\\n  print(markdown_code_fence)\\n  suggestions = []\\n  for (i, check) in enumerate(CHECKS):\\n    if i > 0:\\n      print()\\n    print(\"--- check: %s\" % check.__name__)\\n    try:\\n      suggestions.extend(check())\\n    except Exception:\\n      traceback.print_exc(file=sys.stdout)\\n      pass\\n  print(markdown_code_fence)\\n  print()\\n  print(\"</details>\")\\n\\n  for suggestion in suggestions:\\n    print()\\n    print(\"### Suggestion: %s\" % suggestion.headline)\\n    print()\\n    print(suggestion.description)\\n\\n  print()\\n  print(\"### Next steps\")\\n  print()\\n  if suggestions:\\n    print(reflow(\\n        \"\"\"\\n        Please try each suggestion enumerated above to determine whether\\n        it solves your problem. If none of these suggestions works,\\n        please copy ALL of the above output, including the lines\\n        containing only backticks, into your GitHub issue or comment. Be\\n        sure to redact any sensitive information.\\n        \"\"\"\\n    ))\\n  else:\\n    print(reflow(\\n        \"\"\"\\n        No action items identified. Please copy ALL of the above output,\\n        including the lines containing only backticks, into your GitHub\\n        issue or comment. Be sure to redact any sensitive information.\\n        \"\"\"\\n    ))\\n\\n\\nif __name__ == \"__main__\":\\n  main()'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# Copyright 2019 The TensorFlow Authors. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# ==============================================================================\n",
    "\"\"\"Self-diagnosis script for TensorBoard.\n",
    "\n",
    "Instructions: Save this script to your local machine, then execute it in\n",
    "the same environment (virtualenv, Conda, etc.) from which you normally\n",
    "run TensorBoard. Read the output and follow the directions.\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "# This script may only depend on the Python standard library. It is not\n",
    "# built with Bazel and should not assume any third-party dependencies.\n",
    "import collections\n",
    "import errno\n",
    "import functools\n",
    "import hashlib\n",
    "import inspect\n",
    "import logging\n",
    "import os\n",
    "import pipes\n",
    "import shlex\n",
    "import socket\n",
    "import subprocess\n",
    "import sys\n",
    "import tempfile\n",
    "import textwrap\n",
    "import traceback\n",
    "\n",
    "\n",
    "# A *check* is a function (of no arguments) that performs a diagnostic,\n",
    "# writes log messages, and optionally yields suggestions. Each check\n",
    "# runs in isolation; exceptions will be caught and reported.\n",
    "CHECKS = []\n",
    "\n",
    "\n",
    "# A suggestion to the end user.\n",
    "#   headline (str): A short description, like \"Turn it off and on\n",
    "#     again\". Should be imperative with no trailing punctuation. May\n",
    "#     contain inline Markdown.\n",
    "#   description (str): A full enumeration of the steps that the user\n",
    "#     should take to accept the suggestion. Within this string, prose\n",
    "#     should be formatted with `reflow`. May contain Markdown.\n",
    "Suggestion = collections.namedtuple(\"Suggestion\", (\"headline\", \"description\"))\n",
    "\n",
    "\n",
    "def check(fn):\n",
    "  \"\"\"Decorator to register a function as a check.\n",
    "\n",
    "  Checks are run in the order in which they are registered.\n",
    "\n",
    "  Args:\n",
    "    fn: A function that takes no arguments and either returns `None` or\n",
    "      returns a generator of `Suggestion`s. (The ability to return\n",
    "      `None` is to work around the awkwardness of defining empty\n",
    "      generator functions in Python.)\n",
    "\n",
    "  Returns:\n",
    "    A wrapped version of `fn` that returns a generator of `Suggestion`s.\n",
    "  \"\"\"\n",
    "  @functools.wraps(fn)\n",
    "  def wrapper():\n",
    "    result = fn()\n",
    "    return iter(()) if result is None else result\n",
    "  CHECKS.append(wrapper)\n",
    "  return wrapper\n",
    "\n",
    "\n",
    "def reflow(paragraph):\n",
    "  return textwrap.fill(textwrap.dedent(paragraph).strip())\n",
    "\n",
    "\n",
    "def pip(args):\n",
    "  \"\"\"Invoke command-line Pip with the specified args.\n",
    "\n",
    "  Returns:\n",
    "    A bytestring containing the output of Pip.\n",
    "  \"\"\"\n",
    "  # Suppress the Python 2.7 deprecation warning.\n",
    "  PYTHONWARNINGS_KEY = \"PYTHONWARNINGS\"\n",
    "  old_pythonwarnings = os.environ.get(PYTHONWARNINGS_KEY)\n",
    "  new_pythonwarnings = \"%s%s\" % (\n",
    "      \"ignore:DEPRECATION\",\n",
    "      \",%s\" % old_pythonwarnings if old_pythonwarnings else \"\",\n",
    "  )\n",
    "  command = [sys.executable, \"-m\", \"pip\", \"--disable-pip-version-check\"]\n",
    "  command.extend(args)\n",
    "  try:\n",
    "    os.environ[PYTHONWARNINGS_KEY] = new_pythonwarnings\n",
    "    return subprocess.check_output(command)\n",
    "  finally:\n",
    "    if old_pythonwarnings is None:\n",
    "      del os.environ[PYTHONWARNINGS_KEY]\n",
    "    else:\n",
    "      os.environ[PYTHONWARNINGS_KEY] = old_pythonwarnings\n",
    "\n",
    "\n",
    "def which(name):\n",
    "  \"\"\"Return the path to a binary, or `None` if it's not on the path.\n",
    "\n",
    "  Returns:\n",
    "    A bytestring.\n",
    "  \"\"\"\n",
    "  binary = \"where\" if os.name == \"nt\" else \"which\"\n",
    "  try:\n",
    "    return subprocess.check_output([binary, name])\n",
    "  except subprocess.CalledProcessError:\n",
    "    return None\n",
    "\n",
    "\n",
    "@check\n",
    "def autoidentify():\n",
    "  \"\"\"Print the Git hash of this version of `diagnose_tensorboard.py`.\n",
    "\n",
    "  Given this hash, use `git cat-file blob HASH` to recover the relevant\n",
    "  version of the script.\n",
    "  \"\"\"\n",
    "  module = sys.modules[__name__]\n",
    "  try:\n",
    "    source = inspect.getsource(module).encode(\"utf-8\")\n",
    "  except TypeError:\n",
    "    logging.info(\"diagnose_tensorboard.py source unavailable\")\n",
    "  else:\n",
    "    # Git inserts a length-prefix before hashing; cf. `git-hash-object`.\n",
    "    blob = b\"blob %d\\0%s\" % (len(source), source)\n",
    "    hash = hashlib.sha1(blob).hexdigest()\n",
    "    logging.info(\"diagnose_tensorboard.py version %s\", hash)\n",
    "\n",
    "\n",
    "@check\n",
    "def general():\n",
    "  logging.info(\"sys.version_info: %s\", sys.version_info)\n",
    "  logging.info(\"os.name: %s\", os.name)\n",
    "  na = type(\"N/A\", (object,), {\"__repr__\": lambda self: \"N/A\"})\n",
    "  logging.info(\"os.uname(): %r\", getattr(os, \"uname\", na)(),)\n",
    "  logging.info(\n",
    "      \"sys.getwindowsversion(): %r\",\n",
    "      getattr(sys, \"getwindowsversion\", na)(),\n",
    "  )\n",
    "\n",
    "\n",
    "@check\n",
    "def package_management():\n",
    "  conda_meta = os.path.join(sys.prefix, \"conda-meta\")\n",
    "  logging.info(\"has conda-meta: %s\", os.path.exists(conda_meta))\n",
    "  logging.info(\"$VIRTUAL_ENV: %r\", os.environ.get(\"VIRTUAL_ENV\"))\n",
    "\n",
    "\n",
    "@check\n",
    "def installed_packages():\n",
    "  freeze = pip([\"freeze\", \"--all\"]).decode(\"utf-8\").splitlines()\n",
    "  packages = {line.split(u\"==\")[0]: line for line in freeze}\n",
    "  packages_set = frozenset(packages)\n",
    "\n",
    "  # For each of the following families, expect exactly one package to be\n",
    "  # installed.\n",
    "  expect_unique = [\n",
    "      frozenset([\n",
    "          u\"tensorboard\",\n",
    "          u\"tb-nightly\",\n",
    "          u\"tensorflow-tensorboard\",\n",
    "      ]),\n",
    "      frozenset([\n",
    "          u\"tensorflow\",\n",
    "          u\"tensorflow-gpu\",\n",
    "          u\"tf-nightly\",\n",
    "          u\"tf-nightly-2.0-preview\",\n",
    "          u\"tf-nightly-gpu\",\n",
    "          u\"tf-nightly-gpu-2.0-preview\",\n",
    "      ]),\n",
    "      frozenset([\n",
    "          u\"tensorflow-estimator\",\n",
    "          u\"tensorflow-estimator-2.0-preview\",\n",
    "          u\"tf-estimator-nightly\",\n",
    "      ]),\n",
    "  ]\n",
    "\n",
    "  found_conflict = False\n",
    "  for family in expect_unique:\n",
    "    actual = family & packages_set\n",
    "    for package in actual:\n",
    "      logging.info(\"installed: %s\", packages[package])\n",
    "    if len(actual) == 0:\n",
    "      logging.warning(\"no installation among: %s\", sorted(family))\n",
    "    elif len(actual) > 1:\n",
    "      logging.warning(\"conflicting installations: %s\", sorted(actual))\n",
    "      found_conflict = True\n",
    "\n",
    "  if found_conflict:\n",
    "    preamble = reflow(\n",
    "        \"\"\"\n",
    "        Conflicting package installations found. Depending on the order\n",
    "        of installations and uninstallations, behavior may be undefined.\n",
    "        Please uninstall ALL versions of TensorFlow and TensorBoard,\n",
    "        then reinstall ONLY the desired version of TensorFlow, which\n",
    "        will transitively pull in the proper version of TensorBoard. (If\n",
    "        you use TensorBoard without TensorFlow, just reinstall the\n",
    "        appropriate version of TensorBoard directly.)\n",
    "        \"\"\"\n",
    "    )\n",
    "    packages_to_uninstall = sorted(\n",
    "        frozenset().union(*expect_unique) & packages_set\n",
    "    )\n",
    "    commands = [\n",
    "        \"pip uninstall %s\" % \" \".join(packages_to_uninstall),\n",
    "        \"pip install tensorflow  # or `tensorflow-gpu`, or `tf-nightly`, ...\",\n",
    "    ]\n",
    "    message = \"%s\\n\\nNamely:\\n\\n%s\" % (\n",
    "        preamble,\n",
    "        \"\\n\".join(\"\\t%s\" % c for c in commands),\n",
    "    )\n",
    "    yield Suggestion(\"Fix conflicting installations\", message)\n",
    "\n",
    "\n",
    "@check\n",
    "def tensorboard_python_version():\n",
    "  from tensorboard import version\n",
    "  logging.info(\"tensorboard.version.VERSION: %r\", version.VERSION)\n",
    "\n",
    "\n",
    "@check\n",
    "def tensorflow_python_version():\n",
    "  import tensorflow as tf\n",
    "  logging.info(\"tensorflow.__version__: %r\", tf.__version__)\n",
    "  logging.info(\"tensorflow.__git_version__: %r\", tf.__git_version__)\n",
    "\n",
    "\n",
    "@check\n",
    "def tensorboard_binary_path():\n",
    "  logging.info(\"which tensorboard: %r\", which(\"tensorboard\"))\n",
    "\n",
    "\n",
    "@check\n",
    "def readable_fqdn():\n",
    "  # May raise `UnicodeDecodeError` for non-ASCII hostnames:\n",
    "  # https://github.com/tensorflow/tensorboard/issues/682\n",
    "  try:\n",
    "    logging.info(\"socket.getfqdn(): %r\", socket.getfqdn())\n",
    "  except UnicodeDecodeError as e:\n",
    "    try:\n",
    "      binary_hostname = subprocess.check_output([\"hostname\"]).strip()\n",
    "    except subprocess.CalledProcessError:\n",
    "      binary_hostname = b\"<unavailable>\"\n",
    "    is_non_ascii = not all(\n",
    "        0x20 <= (ord(c) if not isinstance(c, int) else c) <= 0x7E  # Python 2\n",
    "        for c in binary_hostname\n",
    "    )\n",
    "    if is_non_ascii:\n",
    "      message = reflow(\n",
    "          \"\"\"\n",
    "          Your computer's hostname, %r, contains bytes outside of the\n",
    "          printable ASCII range. Some versions of Python have trouble\n",
    "          working with such names (https://bugs.python.org/issue26227).\n",
    "          Consider changing to a hostname that only contains printable\n",
    "          ASCII bytes.\n",
    "          \"\"\" % (binary_hostname,)\n",
    "      )\n",
    "      yield Suggestion(\"Use an ASCII hostname\", message)\n",
    "    else:\n",
    "      message = reflow(\n",
    "          \"\"\"\n",
    "          Python can't read your computer's hostname, %r. This can occur\n",
    "          if the hostname contains non-ASCII bytes\n",
    "          (https://bugs.python.org/issue26227). Consider changing your\n",
    "          hostname, rebooting your machine, and rerunning this diagnosis\n",
    "          script to see if the problem is resolved.\n",
    "          \"\"\" % (binary_hostname,)\n",
    "      )\n",
    "      yield Suggestion(\"Use a simpler hostname\", message)\n",
    "    raise e\n",
    "\n",
    "\n",
    "@check\n",
    "def stat_tensorboardinfo():\n",
    "  # We don't use `manager._get_info_dir`, because (a) that requires\n",
    "  # TensorBoard, and (b) that creates the directory if it doesn't exist.\n",
    "  path = os.path.join(tempfile.gettempdir(), \".tensorboard-info\")\n",
    "  logging.info(\"directory: %s\", path)\n",
    "  try:\n",
    "    stat_result = os.stat(path)\n",
    "  except OSError as e:\n",
    "    if e.errno == errno.ENOENT:\n",
    "      # No problem; this is just fine.\n",
    "      logging.info(\".tensorboard-info directory does not exist\")\n",
    "      return\n",
    "    else:\n",
    "      raise\n",
    "  logging.info(\"os.stat(...): %r\", stat_result)\n",
    "  logging.info(\"mode: 0o%o\", stat_result.st_mode)\n",
    "  if stat_result.st_mode & 0o777 != 0o777:\n",
    "    preamble = reflow(\n",
    "        \"\"\"\n",
    "        The \".tensorboard-info\" directory was created by an old version\n",
    "        of TensorBoard, and its permissions are not set correctly; see\n",
    "        issue #2010. Change that directory to be world-accessible (may\n",
    "        require superuser privilege):\n",
    "        \"\"\"\n",
    "    )\n",
    "    # This error should only appear on Unices, so it's okay to use\n",
    "    # Unix-specific utilities and shell syntax.\n",
    "    quote = getattr(shlex, \"quote\", None) or pipes.quote  # Python <3.3\n",
    "    command = \"chmod 777 %s\" % quote(path)\n",
    "    message = \"%s\\n\\n\\t%s\" % (preamble, command)\n",
    "    yield Suggestion(\"Fix permissions on \\\"%s\\\"\" % path, message)\n",
    "\n",
    "\n",
    "@check\n",
    "def source_trees_without_genfiles():\n",
    "  roots = list(sys.path)\n",
    "  if \"\" not in roots:\n",
    "    # Catch problems that would occur in a Python interactive shell\n",
    "    # (where `\"\"` is prepended to `sys.path`) but not when\n",
    "    # `diagnose_tensorboard.py` is run as a standalone script.\n",
    "    roots.insert(0, \"\")\n",
    "\n",
    "  def has_tensorboard(root):\n",
    "    return os.path.isfile(os.path.join(root, \"tensorboard\", \"__init__.py\"))\n",
    "  def has_genfiles(root):\n",
    "    sample_genfile = os.path.join(\"compat\", \"proto\", \"summary_pb2.py\")\n",
    "    return os.path.isfile(os.path.join(root, \"tensorboard\", sample_genfile))\n",
    "  def is_bad(root):\n",
    "    return has_tensorboard(root) and not has_genfiles(root)\n",
    "\n",
    "  tensorboard_roots = [root for root in roots if has_tensorboard(root)]\n",
    "  bad_roots = [root for root in roots if is_bad(root)]\n",
    "\n",
    "  logging.info(\n",
    "      \"tensorboard_roots (%d): %r; bad_roots (%d): %r\",\n",
    "      len(tensorboard_roots),\n",
    "      tensorboard_roots,\n",
    "      len(bad_roots),\n",
    "      bad_roots,\n",
    "  )\n",
    "\n",
    "  if bad_roots:\n",
    "    if bad_roots == [\"\"]:\n",
    "      message = reflow(\n",
    "          \"\"\"\n",
    "          Your current directory contains a `tensorboard` Python package\n",
    "          that does not include generated files. This can happen if your\n",
    "          current directory includes the TensorBoard source tree (e.g.,\n",
    "          you are in the TensorBoard Git repository). Consider changing\n",
    "          to a different directory.\n",
    "          \"\"\"\n",
    "      )\n",
    "    else:\n",
    "      preamble = reflow(\n",
    "          \"\"\"\n",
    "          Your Python path contains a `tensorboard` package that does\n",
    "          not include generated files. This can happen if your current\n",
    "          directory includes the TensorBoard source tree (e.g., you are\n",
    "          in the TensorBoard Git repository). The following directories\n",
    "          from your Python path may be problematic:\n",
    "          \"\"\"\n",
    "      )\n",
    "      roots = []\n",
    "      realpaths_seen = set()\n",
    "      for root in bad_roots:\n",
    "        label = repr(root) if root else \"current directory\"\n",
    "        realpath = os.path.realpath(root)\n",
    "        if realpath in realpaths_seen:\n",
    "          # virtualenvs on Ubuntu install to both `lib` and `local/lib`;\n",
    "          # explicitly call out such duplicates to avoid confusion.\n",
    "          label += \" (duplicate underlying directory)\"\n",
    "        realpaths_seen.add(realpath)\n",
    "        roots.append(label)\n",
    "      message = \"%s\\n\\n%s\" % (preamble, \"\\n\".join(\"  - %s\" % s for s in roots))\n",
    "    yield Suggestion(\"Avoid `tensorboard` packages without genfiles\", message)\n",
    "\n",
    "\n",
    "# Prefer to include this check last, as its output is long.\n",
    "@check\n",
    "def full_pip_freeze():\n",
    "  logging.info(\"pip freeze --all:\\n%s\", pip([\"freeze\", \"--all\"]).decode(\"utf-8\"))\n",
    "\n",
    "\n",
    "def set_up_logging():\n",
    "  # Manually install handlers to prevent TensorFlow from stomping the\n",
    "  # default configuration if it's imported:\n",
    "  # https://github.com/tensorflow/tensorflow/issues/28147\n",
    "  logger = logging.getLogger()\n",
    "  logger.setLevel(logging.INFO)\n",
    "  handler = logging.StreamHandler(sys.stdout)\n",
    "  handler.setFormatter(logging.Formatter(\"%(levelname)s: %(message)s\"))\n",
    "  logger.addHandler(handler)\n",
    "\n",
    "\n",
    "def main():\n",
    "  set_up_logging()\n",
    "\n",
    "  print(\"### Diagnostics\")\n",
    "  print()\n",
    "\n",
    "  print(\"<details>\")\n",
    "  print(\"<summary>Diagnostics output</summary>\")\n",
    "  print()\n",
    "\n",
    "  markdown_code_fence = \"``````\"  # seems likely to be sufficient\n",
    "  print(markdown_code_fence)\n",
    "  suggestions = []\n",
    "  for (i, check) in enumerate(CHECKS):\n",
    "    if i > 0:\n",
    "      print()\n",
    "    print(\"--- check: %s\" % check.__name__)\n",
    "    try:\n",
    "      suggestions.extend(check())\n",
    "    except Exception:\n",
    "      traceback.print_exc(file=sys.stdout)\n",
    "      pass\n",
    "  print(markdown_code_fence)\n",
    "  print()\n",
    "  print(\"</details>\")\n",
    "\n",
    "  for suggestion in suggestions:\n",
    "    print()\n",
    "    print(\"### Suggestion: %s\" % suggestion.headline)\n",
    "    print()\n",
    "    print(suggestion.description)\n",
    "\n",
    "  print()\n",
    "  print(\"### Next steps\")\n",
    "  print()\n",
    "  if suggestions:\n",
    "    print(reflow(\n",
    "        \"\"\"\n",
    "        Please try each suggestion enumerated above to determine whether\n",
    "        it solves your problem. If none of these suggestions works,\n",
    "        please copy ALL of the above output, including the lines\n",
    "        containing only backticks, into your GitHub issue or comment. Be\n",
    "        sure to redact any sensitive information.\n",
    "        \"\"\"\n",
    "    ))\n",
    "  else:\n",
    "    print(reflow(\n",
    "        \"\"\"\n",
    "        No action items identified. Please copy ALL of the above output,\n",
    "        including the lines containing only backticks, into your GitHub\n",
    "        issue or comment. Be sure to redact any sensitive information.\n",
    "        \"\"\"\n",
    "    ))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "  main()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the TensorBoard notebook extension.\n",
    "%load_ext tensorboard\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "from datetime import datetime\n",
    "#from packaging import version\n",
    "logdir=\"logs/fit/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "!rm -rf ./logs/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 8\n",
    "np.random.seed(seed)\n",
    "model = keras.Sequential([\n",
    "#    keras.layers.Flatten(input_shape=(1, 6)),\n",
    "#    keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(30, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(64, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(64, activation=tf.nn.relu),\n",
    "    #keras.layers.Dense(2, activation=tf.nn.softmax)\n",
    "    #keras.layers.Dense(1, activation='tanh') #!!!!! 5 = number of categorical values in categorical classifier\n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "   \n",
    "])\n",
    "\n",
    "\n",
    "#Re(ctified) L(inear) (U)nit\n",
    "#nn = neuralnet\n",
    "#softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "              optimizer= \"rmsprop\", \n",
    "#             optimizer='sgd', \n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "#sgd = gradient descent (steepness of move)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 189 samples\n",
      "Epoch 1/100\n",
      "189/189 [==============================] - 1s 7ms/sample - loss: 0.6505 - accuracy: 0.6138\n",
      "Epoch 2/100\n",
      "189/189 [==============================] - 0s 282us/sample - loss: 0.5429 - accuracy: 0.7884\n",
      "Epoch 3/100\n",
      "189/189 [==============================] - 0s 311us/sample - loss: 0.4624 - accuracy: 0.8148\n",
      "Epoch 4/100\n",
      "189/189 [==============================] - 0s 246us/sample - loss: 0.4192 - accuracy: 0.8148\n",
      "Epoch 5/100\n",
      "189/189 [==============================] - 0s 261us/sample - loss: 0.4009 - accuracy: 0.8148\n",
      "Epoch 6/100\n",
      "189/189 [==============================] - 0s 277us/sample - loss: 0.3837 - accuracy: 0.8307\n",
      "Epoch 7/100\n",
      "189/189 [==============================] - 0s 269us/sample - loss: 0.3704 - accuracy: 0.8413\n",
      "Epoch 8/100\n",
      "189/189 [==============================] - 0s 234us/sample - loss: 0.3589 - accuracy: 0.8571\n",
      "Epoch 9/100\n",
      "189/189 [==============================] - 0s 251us/sample - loss: 0.3482 - accuracy: 0.8571\n",
      "Epoch 10/100\n",
      "189/189 [==============================] - 0s 201us/sample - loss: 0.3378 - accuracy: 0.8519\n",
      "Epoch 11/100\n",
      "189/189 [==============================] - 0s 225us/sample - loss: 0.3329 - accuracy: 0.8571\n",
      "Epoch 12/100\n",
      "189/189 [==============================] - 0s 250us/sample - loss: 0.3244 - accuracy: 0.8677\n",
      "Epoch 13/100\n",
      "189/189 [==============================] - 0s 258us/sample - loss: 0.3113 - accuracy: 0.8519\n",
      "Epoch 14/100\n",
      "189/189 [==============================] - 0s 248us/sample - loss: 0.2991 - accuracy: 0.8889\n",
      "Epoch 15/100\n",
      "189/189 [==============================] - 0s 248us/sample - loss: 0.2995 - accuracy: 0.8677\n",
      "Epoch 16/100\n",
      "189/189 [==============================] - 0s 247us/sample - loss: 0.2924 - accuracy: 0.8783\n",
      "Epoch 17/100\n",
      "189/189 [==============================] - 0s 307us/sample - loss: 0.2868 - accuracy: 0.8730\n",
      "Epoch 18/100\n",
      "189/189 [==============================] - 0s 275us/sample - loss: 0.2727 - accuracy: 0.8836\n",
      "Epoch 19/100\n",
      "189/189 [==============================] - 0s 247us/sample - loss: 0.2613 - accuracy: 0.8730\n",
      "Epoch 20/100\n",
      "189/189 [==============================] - 0s 252us/sample - loss: 0.2611 - accuracy: 0.8995\n",
      "Epoch 21/100\n",
      "189/189 [==============================] - 0s 380us/sample - loss: 0.2566 - accuracy: 0.8889\n",
      "Epoch 22/100\n",
      "189/189 [==============================] - 0s 322us/sample - loss: 0.2494 - accuracy: 0.8995\n",
      "Epoch 23/100\n",
      "189/189 [==============================] - 0s 275us/sample - loss: 0.2419 - accuracy: 0.8995\n",
      "Epoch 24/100\n",
      "189/189 [==============================] - 0s 253us/sample - loss: 0.2396 - accuracy: 0.8942\n",
      "Epoch 25/100\n",
      "189/189 [==============================] - 0s 267us/sample - loss: 0.2252 - accuracy: 0.8942\n",
      "Epoch 26/100\n",
      "189/189 [==============================] - 0s 281us/sample - loss: 0.2299 - accuracy: 0.8995\n",
      "Epoch 27/100\n",
      "189/189 [==============================] - 0s 252us/sample - loss: 0.2189 - accuracy: 0.8995\n",
      "Epoch 28/100\n",
      "189/189 [==============================] - 0s 436us/sample - loss: 0.2149 - accuracy: 0.9153\n",
      "Epoch 29/100\n",
      "189/189 [==============================] - 0s 551us/sample - loss: 0.2078 - accuracy: 0.9206\n",
      "Epoch 30/100\n",
      "189/189 [==============================] - 0s 378us/sample - loss: 0.1987 - accuracy: 0.9048\n",
      "Epoch 31/100\n",
      "189/189 [==============================] - 0s 285us/sample - loss: 0.2006 - accuracy: 0.9153\n",
      "Epoch 32/100\n",
      "189/189 [==============================] - 0s 293us/sample - loss: 0.1991 - accuracy: 0.9153\n",
      "Epoch 33/100\n",
      "189/189 [==============================] - 0s 283us/sample - loss: 0.1845 - accuracy: 0.9365\n",
      "Epoch 34/100\n",
      "189/189 [==============================] - 0s 279us/sample - loss: 0.1821 - accuracy: 0.9206\n",
      "Epoch 35/100\n",
      "189/189 [==============================] - 0s 258us/sample - loss: 0.1803 - accuracy: 0.9153\n",
      "Epoch 36/100\n",
      "189/189 [==============================] - 0s 371us/sample - loss: 0.1821 - accuracy: 0.9048\n",
      "Epoch 37/100\n",
      "189/189 [==============================] - 0s 518us/sample - loss: 0.1658 - accuracy: 0.9312\n",
      "Epoch 38/100\n",
      "189/189 [==============================] - 0s 358us/sample - loss: 0.1674 - accuracy: 0.9259\n",
      "Epoch 39/100\n",
      "189/189 [==============================] - 0s 349us/sample - loss: 0.1589 - accuracy: 0.9312\n",
      "Epoch 40/100\n",
      "189/189 [==============================] - 0s 464us/sample - loss: 0.1535 - accuracy: 0.9365\n",
      "Epoch 41/100\n",
      "189/189 [==============================] - 0s 969us/sample - loss: 0.1525 - accuracy: 0.9418\n",
      "Epoch 42/100\n",
      "189/189 [==============================] - 0s 328us/sample - loss: 0.1450 - accuracy: 0.9577\n",
      "Epoch 43/100\n",
      "189/189 [==============================] - 0s 492us/sample - loss: 0.1371 - accuracy: 0.9471\n",
      "Epoch 44/100\n",
      "189/189 [==============================] - 0s 478us/sample - loss: 0.1435 - accuracy: 0.9471\n",
      "Epoch 45/100\n",
      "189/189 [==============================] - 0s 697us/sample - loss: 0.1388 - accuracy: 0.9418\n",
      "Epoch 46/100\n",
      "189/189 [==============================] - 0s 343us/sample - loss: 0.1331 - accuracy: 0.9524\n",
      "Epoch 47/100\n",
      "189/189 [==============================] - 0s 275us/sample - loss: 0.1272 - accuracy: 0.9524\n",
      "Epoch 48/100\n",
      "189/189 [==============================] - 0s 388us/sample - loss: 0.1403 - accuracy: 0.9524\n",
      "Epoch 49/100\n",
      "189/189 [==============================] - 0s 390us/sample - loss: 0.1152 - accuracy: 0.9524\n",
      "Epoch 50/100\n",
      "189/189 [==============================] - 0s 273us/sample - loss: 0.1086 - accuracy: 0.9683\n",
      "Epoch 51/100\n",
      "189/189 [==============================] - 0s 268us/sample - loss: 0.1325 - accuracy: 0.9365\n",
      "Epoch 52/100\n",
      "189/189 [==============================] - 0s 411us/sample - loss: 0.1068 - accuracy: 0.9683\n",
      "Epoch 53/100\n",
      "189/189 [==============================] - 0s 241us/sample - loss: 0.1141 - accuracy: 0.9524\n",
      "Epoch 54/100\n",
      "189/189 [==============================] - 0s 239us/sample - loss: 0.1106 - accuracy: 0.9524\n",
      "Epoch 55/100\n",
      "189/189 [==============================] - 0s 249us/sample - loss: 0.0970 - accuracy: 0.9577\n",
      "Epoch 56/100\n",
      "189/189 [==============================] - 0s 198us/sample - loss: 0.1186 - accuracy: 0.9471\n",
      "Epoch 57/100\n",
      "189/189 [==============================] - 0s 218us/sample - loss: 0.0954 - accuracy: 0.9683\n",
      "Epoch 58/100\n",
      "189/189 [==============================] - 0s 258us/sample - loss: 0.0976 - accuracy: 0.9577\n",
      "Epoch 59/100\n",
      "189/189 [==============================] - 0s 228us/sample - loss: 0.0955 - accuracy: 0.9735\n",
      "Epoch 60/100\n",
      "189/189 [==============================] - 0s 330us/sample - loss: 0.0923 - accuracy: 0.9683\n",
      "Epoch 61/100\n",
      "189/189 [==============================] - 0s 315us/sample - loss: 0.0899 - accuracy: 0.9630\n",
      "Epoch 62/100\n",
      "189/189 [==============================] - 0s 300us/sample - loss: 0.0892 - accuracy: 0.9630\n",
      "Epoch 63/100\n",
      "189/189 [==============================] - 0s 285us/sample - loss: 0.0814 - accuracy: 0.9683\n",
      "Epoch 64/100\n",
      "189/189 [==============================] - 0s 280us/sample - loss: 0.0834 - accuracy: 0.9630\n",
      "Epoch 65/100\n",
      "189/189 [==============================] - 0s 249us/sample - loss: 0.0890 - accuracy: 0.9683\n",
      "Epoch 66/100\n",
      "189/189 [==============================] - 0s 509us/sample - loss: 0.0782 - accuracy: 0.9735\n",
      "Epoch 67/100\n",
      "189/189 [==============================] - 0s 218us/sample - loss: 0.0742 - accuracy: 0.9735\n",
      "Epoch 68/100\n",
      "189/189 [==============================] - 0s 274us/sample - loss: 0.0768 - accuracy: 0.9841\n",
      "Epoch 69/100\n",
      "189/189 [==============================] - 0s 269us/sample - loss: 0.0788 - accuracy: 0.9788\n",
      "Epoch 70/100\n",
      "189/189 [==============================] - 0s 179us/sample - loss: 0.0664 - accuracy: 0.9735\n",
      "Epoch 71/100\n",
      "189/189 [==============================] - 0s 277us/sample - loss: 0.0723 - accuracy: 0.9788\n",
      "Epoch 72/100\n",
      "189/189 [==============================] - 0s 348us/sample - loss: 0.0730 - accuracy: 0.9788\n",
      "Epoch 73/100\n",
      "189/189 [==============================] - 0s 197us/sample - loss: 0.0752 - accuracy: 0.9683\n",
      "Epoch 74/100\n",
      "189/189 [==============================] - 0s 192us/sample - loss: 0.0656 - accuracy: 0.9735\n",
      "Epoch 75/100\n",
      "189/189 [==============================] - 0s 237us/sample - loss: 0.0673 - accuracy: 0.9735\n",
      "Epoch 76/100\n",
      "189/189 [==============================] - 0s 483us/sample - loss: 0.0618 - accuracy: 0.9683\n",
      "Epoch 77/100\n",
      "189/189 [==============================] - 0s 242us/sample - loss: 0.0587 - accuracy: 0.9683\n",
      "Epoch 78/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "189/189 [==============================] - 0s 185us/sample - loss: 0.0662 - accuracy: 0.9735\n",
      "Epoch 79/100\n",
      "189/189 [==============================] - 0s 177us/sample - loss: 0.0581 - accuracy: 0.9788\n",
      "Epoch 80/100\n",
      "189/189 [==============================] - ETA: 0s - loss: 0.1451 - accuracy: 0.93 - 0s 229us/sample - loss: 0.0500 - accuracy: 0.9841\n",
      "Epoch 81/100\n",
      "189/189 [==============================] - 0s 191us/sample - loss: 0.0563 - accuracy: 0.9788\n",
      "Epoch 82/100\n",
      "189/189 [==============================] - 0s 273us/sample - loss: 0.0496 - accuracy: 0.9735\n",
      "Epoch 83/100\n",
      "189/189 [==============================] - 0s 274us/sample - loss: 0.0543 - accuracy: 0.9735\n",
      "Epoch 84/100\n",
      "189/189 [==============================] - ETA: 0s - loss: 0.0547 - accuracy: 1.00 - 0s 270us/sample - loss: 0.0605 - accuracy: 0.9735\n",
      "Epoch 85/100\n",
      "189/189 [==============================] - 0s 181us/sample - loss: 0.0443 - accuracy: 0.9841\n",
      "Epoch 86/100\n",
      "189/189 [==============================] - 0s 220us/sample - loss: 0.0482 - accuracy: 0.9841\n",
      "Epoch 87/100\n",
      "189/189 [==============================] - 0s 477us/sample - loss: 0.0591 - accuracy: 0.9735\n",
      "Epoch 88/100\n",
      "189/189 [==============================] - 0s 340us/sample - loss: 0.0489 - accuracy: 0.9841\n",
      "Epoch 89/100\n",
      "189/189 [==============================] - 0s 541us/sample - loss: 0.0396 - accuracy: 0.9788\n",
      "Epoch 90/100\n",
      "189/189 [==============================] - 0s 309us/sample - loss: 0.0459 - accuracy: 0.9683\n",
      "Epoch 91/100\n",
      "189/189 [==============================] - 0s 232us/sample - loss: 0.0469 - accuracy: 0.9894\n",
      "Epoch 92/100\n",
      "189/189 [==============================] - 0s 228us/sample - loss: 0.0424 - accuracy: 0.9841\n",
      "Epoch 93/100\n",
      "189/189 [==============================] - 0s 221us/sample - loss: 0.0443 - accuracy: 0.9683\n",
      "Epoch 94/100\n",
      "189/189 [==============================] - 0s 158us/sample - loss: 0.0440 - accuracy: 0.9788\n",
      "Epoch 95/100\n",
      "189/189 [==============================] - 0s 214us/sample - loss: 0.0366 - accuracy: 0.9894\n",
      "Epoch 96/100\n",
      "189/189 [==============================] - 0s 347us/sample - loss: 0.0428 - accuracy: 0.9841\n",
      "Epoch 97/100\n",
      "189/189 [==============================] - 0s 275us/sample - loss: 0.0378 - accuracy: 0.9947\n",
      "Epoch 98/100\n",
      "189/189 [==============================] - 0s 282us/sample - loss: 0.0323 - accuracy: 0.9894\n",
      "Epoch 99/100\n",
      "189/189 [==============================] - 0s 240us/sample - loss: 0.0421 - accuracy: 0.9894\n",
      "Epoch 100/100\n",
      "189/189 [==============================] - 0s 267us/sample - loss: 0.0342 - accuracy: 0.9841\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train, train_label, epochs=100, batch_size = 15,callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81/1 [==============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 2ms/sample - loss: 1.0758 - accuracy: 0.8148\n",
      "Train accuracy: 0.8148148\n",
      "Train loss: 1.1368951900505726\n"
     ]
    }
   ],
   "source": [
    "train_loss, train_acc = model.evaluate(test, test_label)\n",
    "\n",
    "print('Train accuracy:', train_acc)\n",
    "print('Train loss:', train_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-bbc6673d9eb43699\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-bbc6673d9eb43699\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          url.port = 6007;\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tensorflow.python.keras.callbacks.History object at 0x1431f6198>\n",
      " \n",
      " \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(history)\n",
    "#print('Train: %.3f, Test: %.3f' % (train_acc, test_acc))\n",
    "# plot loss during training\n",
    "plt.subplot(211)\n",
    "plt.title('Loss')\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "#plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "print(\" \")\n",
    "print(\" \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot accuracy during training\n",
    "plt.subplot(212)\n",
    "plt.title('Accuracy')\n",
    "plt.plot(history.history['accuracy'], label='train')\n",
    "#plt.plot(history.history['val_accuracy'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: MacOSX\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1403ecdd8>"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#from keras.utils import plot_model\n",
    "#plot_model(model, expand_nested = True, show_shapes = True)\n",
    "\n",
    "from IPython.display import SVG\n",
    "from keras.utils import model_to_dot\n",
    "\n",
    "import io\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib\n",
    "\n",
    "img = io.BytesIO()\n",
    "png_img = model_to_dot(model).create(prog='dot', format='png')\n",
    "img.write(png_img)\n",
    "img.seek(0)\n",
    "img = mpimg.imread(img)\n",
    "plt.imshow(img)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.68109143e-02]\n",
      " [7.91609287e-04]\n",
      " [1.00000000e+00]\n",
      " [1.05190277e-03]\n",
      " [1.18017197e-05]\n",
      " [4.34237719e-03]\n",
      " [3.27825546e-07]\n",
      " [0.00000000e+00]\n",
      " [9.98930156e-01]\n",
      " [1.00000000e+00]\n",
      " [1.22231245e-02]\n",
      " [4.70578671e-05]\n",
      " [9.99814928e-01]\n",
      " [9.83773589e-01]\n",
      " [8.94069672e-08]\n",
      " [5.06639481e-07]\n",
      " [1.00000000e+00]\n",
      " [9.99969959e-01]\n",
      " [4.24377710e-01]\n",
      " [1.60932541e-06]\n",
      " [1.19209290e-07]\n",
      " [5.22850335e-01]\n",
      " [2.68220901e-07]\n",
      " [1.10268593e-06]\n",
      " [3.69723618e-01]\n",
      " [0.00000000e+00]\n",
      " [9.38340664e-01]\n",
      " [2.97419667e-01]\n",
      " [2.93016434e-04]\n",
      " [9.99999881e-01]\n",
      " [1.13248825e-06]\n",
      " [1.00000000e+00]\n",
      " [9.05990601e-06]\n",
      " [9.99999523e-01]\n",
      " [1.79708004e-05]\n",
      " [8.64267349e-07]\n",
      " [9.99997497e-01]\n",
      " [5.96046448e-08]\n",
      " [2.47088075e-03]\n",
      " [3.25527787e-03]\n",
      " [0.00000000e+00]\n",
      " [9.99999523e-01]\n",
      " [0.00000000e+00]\n",
      " [3.02270055e-03]\n",
      " [9.99933898e-01]\n",
      " [4.04421300e-01]\n",
      " [5.69655478e-01]\n",
      " [9.97240424e-01]\n",
      " [8.80002975e-04]\n",
      " [0.00000000e+00]\n",
      " [1.00000000e+00]\n",
      " [9.93406534e-01]\n",
      " [4.17232513e-07]\n",
      " [9.89029169e-01]\n",
      " [2.09212303e-05]\n",
      " [6.56509399e-03]\n",
      " [8.67933035e-04]\n",
      " [5.51342964e-06]\n",
      " [4.22596931e-05]\n",
      " [9.99999881e-01]\n",
      " [9.99999404e-01]\n",
      " [1.62129700e-02]\n",
      " [1.51664019e-04]\n",
      " [5.79363108e-03]\n",
      " [8.75452161e-03]\n",
      " [1.00000000e+00]\n",
      " [9.53674316e-07]\n",
      " [5.12123108e-04]\n",
      " [5.34945726e-03]\n",
      " [4.35760617e-03]\n",
      " [2.31064707e-01]\n",
      " [9.99998987e-01]\n",
      " [9.99809802e-01]\n",
      " [5.04404306e-04]\n",
      " [1.00000000e+00]\n",
      " [9.99976873e-01]\n",
      " [9.99667168e-01]\n",
      " [3.87430191e-07]\n",
      " [1.15343928e-03]\n",
      " [4.82889891e-01]\n",
      " [1.07130931e-04]]\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(test)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43 0 38 0\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp  = confusion_matrix(test_label, predictions.argmax(axis=1)).ravel()\n",
    "print(tn,fp,fn,tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = [\"Absence\",\"Presence\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image(i, predictions_array, true_label):\n",
    "  predictions_array, true_label = predictions_array[i], true_label[i][0]\n",
    "  plt.grid(False)\n",
    "  plt.xticks([])\n",
    "  plt.yticks([])\n",
    "  \n",
    "\n",
    "\n",
    "  predicted_label = np.argmax(predictions_array)\n",
    "  if predicted_label == true_label:\n",
    "    color = 'blue'\n",
    "  else:\n",
    "    color = 'red'\n",
    "  \n",
    "  plt.xlabel(\"{} {:2.0f}% ({})\".format(class_names[predicted_label],\n",
    "                                100*np.max(predictions_array),\n",
    "                                class_names[true_label]),\n",
    "                                color=color)\n",
    "\n",
    "def plot_value_array(i, predictions_array, true_label):\n",
    "  predictions_array, true_label = predictions_array[i], true_label[i][0]\n",
    "  plt.grid(True)\n",
    "  plt.xticks([])\n",
    "  #plt.yticks([])\n",
    "  thisplot = plt.bar(range(2), predictions_array, color=\"#777777\")\n",
    "  plt.ylim([0, 1]) \n",
    "  predicted_label = np.argmax(predictions_array)\n",
    " \n",
    "  thisplot[predicted_label].set_color('red')\n",
    "  thisplot[true_label].set_color('blue')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_label = test_label.astype(int)\n",
    "test = test.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "\n",
    "plt.figure(figsize=(6,3))\n",
    "plt.subplot(1,2,1)\n",
    "plot_image(i, predictions, test)\n",
    "plt.subplot(1,2,2)\n",
    "plot_value_array(i, predictions, test_label)\n",
    "plt.xticks(range(2), class_names, rotation=45)\n",
    "plt.show()\n",
    "# Blue bar is correct.  If red bar appears, it is the incorrect prediction of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "num_rows = 4\n",
    "num_cols = 4\n",
    "num_images = num_rows*num_cols\n",
    "plt.figure(figsize=(2*2*num_cols, 2*num_rows))\n",
    "for i in range(num_images):\n",
    "    plt.subplot(num_rows, 2*num_cols, 2*i+1)\n",
    "    plot_image(i, predictions, test_label)\n",
    "    plt.subplot(num_rows, 2*num_cols, 2*i+2)\n",
    "    plot_value_array(i, predictions, test_label)\n",
    "    plt.xticks(range(2), class_names, rotation=45)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer0 = model.get_layer(index=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 1.09069988e-01, -2.87573814e-01, -2.23594517e-01,\n",
       "         -4.43221815e-02,  6.99656233e-02,  1.98304400e-01,\n",
       "          1.93546906e-01,  5.66738509e-02, -2.90854543e-01,\n",
       "          1.52246431e-01,  1.82592362e-01,  1.11053601e-01,\n",
       "          5.11174276e-02,  2.63167530e-01, -1.45223603e-01,\n",
       "          3.08654547e-01,  6.44980138e-03, -2.81625062e-01,\n",
       "          1.07838787e-01, -6.62568361e-02, -2.25442514e-01,\n",
       "          1.54066309e-01,  3.09839044e-02, -2.01723754e-01,\n",
       "          2.78022766e-01,  2.56228298e-01,  1.58240259e-01,\n",
       "         -1.93813205e-01,  2.31730178e-01,  2.58179724e-01],\n",
       "        [-2.77997226e-01,  2.72120591e-02,  2.00069379e-02,\n",
       "         -1.65922627e-01, -7.84215927e-02,  2.37977996e-01,\n",
       "          8.74396935e-02, -1.35304645e-01, -3.38924378e-01,\n",
       "          1.67984031e-02,  2.67342538e-01,  6.94078356e-02,\n",
       "         -2.23460849e-02, -1.79217532e-02, -2.82697231e-01,\n",
       "         -2.32045844e-01,  1.17512882e-01, -2.36623019e-01,\n",
       "          5.48212342e-02, -2.63546169e-01,  5.81098907e-02,\n",
       "          1.03547677e-01,  2.99191475e-01,  3.57452370e-02,\n",
       "          3.77314806e-01,  2.82508373e-01,  3.27967763e-01,\n",
       "         -2.19259441e-01,  1.72024250e-01,  1.44291788e-01],\n",
       "        [-2.64857382e-01, -2.73189425e-01, -1.60698950e-01,\n",
       "         -2.48717219e-02,  6.05081320e-02, -1.58980265e-01,\n",
       "         -1.96082532e-01, -9.44012329e-02, -2.87838280e-01,\n",
       "         -3.36465061e-01,  4.19774763e-02,  3.04802150e-01,\n",
       "          1.78839862e-01,  2.74904966e-01, -1.84658334e-01,\n",
       "          5.89201897e-02, -3.44700776e-02, -2.47625411e-01,\n",
       "         -5.79396449e-02,  7.67952204e-02,  1.32842660e-01,\n",
       "          2.14759201e-01,  4.00269665e-02, -2.92489380e-01,\n",
       "          3.79292011e-01,  9.77861509e-02, -1.92036331e-01,\n",
       "          5.95849231e-02,  1.92330644e-01,  2.79442251e-01],\n",
       "        [ 3.28791618e-01,  2.99488515e-01, -9.53430012e-02,\n",
       "          3.05438250e-01,  7.48591572e-02,  3.04204166e-01,\n",
       "         -1.67481471e-02,  3.22291031e-02, -2.94461936e-01,\n",
       "          3.52944613e-01, -2.04939600e-02, -2.32626781e-01,\n",
       "          1.67003442e-02, -5.24105728e-02,  3.07738632e-01,\n",
       "          3.47238034e-01, -1.93891689e-01,  3.22249204e-01,\n",
       "          5.58508597e-02,  7.83562288e-03,  3.06589365e-01,\n",
       "          1.85339078e-01, -1.89224526e-01,  3.02201390e-01,\n",
       "          3.60535532e-01,  2.83159226e-01, -1.72998101e-01,\n",
       "         -1.54186621e-01,  2.19095841e-01, -2.96412557e-01],\n",
       "        [ 2.11743027e-01, -2.81543106e-01,  7.59593621e-02,\n",
       "         -1.45685941e-01, -3.22914511e-01,  1.43368647e-01,\n",
       "         -1.51118055e-01, -1.26178071e-01, -1.65357749e-04,\n",
       "         -2.56074481e-02,  2.28913888e-01, -1.46581680e-01,\n",
       "         -1.06640026e-01, -2.79590964e-01, -1.43819168e-01,\n",
       "         -4.18929197e-02,  7.60528073e-02, -1.23722680e-01,\n",
       "         -1.13629282e-01, -1.44864574e-01, -1.17078252e-01,\n",
       "          4.53425460e-02,  6.23720558e-03, -3.14794421e-01,\n",
       "          1.31009996e-01,  2.43380278e-01, -2.42080227e-01,\n",
       "         -1.73096851e-01, -1.55237108e-01,  1.05622202e-01],\n",
       "        [-1.71656191e-01, -1.83043182e-01, -2.44175360e-01,\n",
       "          3.48638892e-02,  3.04663360e-01, -2.49837771e-01,\n",
       "          2.92741001e-01,  3.09446398e-02, -1.60952285e-02,\n",
       "          6.60315007e-02, -8.08560774e-02, -2.47743115e-01,\n",
       "         -1.57048598e-01, -1.89288616e-01, -7.91277885e-02,\n",
       "          1.09671637e-01, -1.20472852e-02, -3.13489288e-01,\n",
       "          2.02263564e-01,  3.66515785e-01, -4.46716025e-02,\n",
       "          7.57680163e-02,  4.97743450e-02, -2.49826625e-01,\n",
       "          3.58472094e-02, -2.19861373e-01, -1.25866175e-01,\n",
       "          2.81013548e-01,  3.13705236e-01, -1.60768047e-01],\n",
       "        [-2.34171659e-01,  2.63350368e-01, -1.28029689e-01,\n",
       "          2.68837720e-01,  2.28448939e-02, -1.88306332e-01,\n",
       "          7.16527849e-02, -8.04368407e-02,  2.18535513e-01,\n",
       "         -1.71827763e-01, -1.77476972e-01,  1.85107648e-01,\n",
       "          3.43238600e-02, -2.96202898e-01,  1.45067707e-01,\n",
       "         -9.29882526e-02, -3.81246619e-02,  2.36775994e-01,\n",
       "          3.96569557e-02, -5.38935028e-02,  1.86187804e-01,\n",
       "          9.35455561e-02,  9.75971594e-02,  2.09675997e-01,\n",
       "          1.62871152e-01,  2.09991172e-01, -6.40052184e-03,\n",
       "          6.49371073e-02,  3.13218921e-01,  1.64383426e-01],\n",
       "        [-2.87491977e-01, -1.37449369e-01, -1.97192550e-01,\n",
       "         -2.13282764e-01,  1.51441246e-01, -5.72681688e-02,\n",
       "         -1.41961142e-01, -1.94492966e-01, -1.40187386e-02,\n",
       "          9.54642147e-03,  3.47564131e-01, -3.47483337e-01,\n",
       "         -8.45966712e-02, -2.83874065e-01, -1.93468869e-01,\n",
       "         -1.55358613e-01,  2.56738991e-01,  8.96262228e-02,\n",
       "          2.73946851e-01, -5.68059459e-02, -1.26623049e-01,\n",
       "         -2.82730609e-01,  5.83200268e-02, -2.66285259e-02,\n",
       "         -1.51563480e-01, -2.92007685e-01,  6.98589012e-02,\n",
       "          2.80787826e-01, -2.02072546e-01, -2.29874760e-01],\n",
       "        [-5.08957580e-02,  2.47714967e-01,  1.19571030e-01,\n",
       "         -1.69421881e-01, -1.32951066e-02,  5.15644858e-03,\n",
       "          1.64083436e-01,  6.25841916e-02,  1.23421893e-01,\n",
       "          1.10884316e-01,  1.71223521e-01, -2.49304727e-01,\n",
       "         -1.87100843e-01, -1.38918146e-01,  1.82191417e-01,\n",
       "         -1.50008515e-01,  2.80592948e-01, -1.47050336e-01,\n",
       "          8.51666331e-02, -6.01395294e-02, -2.68613100e-02,\n",
       "         -9.24419910e-02,  3.13605517e-01, -2.42608443e-01,\n",
       "         -2.05893010e-01,  2.98066318e-01, -2.04846621e-01,\n",
       "          2.83467650e-01,  3.16772223e-01,  2.61105806e-01],\n",
       "        [ 1.19378120e-01,  1.90750301e-01, -3.86040993e-02,\n",
       "          2.13925704e-01,  2.87119091e-01, -1.32787183e-01,\n",
       "          2.43020013e-01,  2.21022412e-01,  2.92450786e-01,\n",
       "         -5.57107776e-02,  1.20311022e-01, -1.96639076e-01,\n",
       "          8.09864476e-02, -1.26429712e-02, -1.22742876e-01,\n",
       "         -2.41416484e-01, -1.74812321e-02, -1.68403655e-01,\n",
       "         -8.32320824e-02,  2.55395055e-01, -1.26379058e-01,\n",
       "         -1.19466044e-01,  1.63694635e-01,  2.78910607e-01,\n",
       "          9.92323160e-02,  2.51252204e-01,  2.78255731e-01,\n",
       "         -9.60967243e-02, -6.99728727e-02, -1.13376379e-01],\n",
       "        [-2.24807739e-01, -3.07680340e-04, -1.23116627e-01,\n",
       "          2.13949770e-01, -1.94071513e-02, -1.83665752e-01,\n",
       "         -9.22436044e-02, -1.61773376e-02,  4.94340584e-02,\n",
       "         -3.22427340e-02, -2.47860983e-01,  7.68246725e-02,\n",
       "          1.37982532e-01, -3.32489878e-01,  1.77017868e-01,\n",
       "          1.91993833e-01, -1.19532458e-01,  2.28432059e-01,\n",
       "          6.65522590e-02,  4.86197658e-02, -1.19032517e-01,\n",
       "          1.08693421e-01,  1.28543422e-01, -1.80748031e-01,\n",
       "          2.17942163e-01,  8.68347194e-03,  5.40656038e-02,\n",
       "         -1.77964032e-01,  2.63869405e-01,  9.62692797e-02],\n",
       "        [ 2.66507268e-01,  1.28791109e-01,  1.75581560e-01,\n",
       "          2.13881537e-01, -2.28436783e-01, -7.69315362e-02,\n",
       "          2.51802057e-01,  6.37601018e-02, -7.32442364e-02,\n",
       "         -7.45489523e-02, -2.50517547e-01, -1.08367078e-01,\n",
       "         -2.67477334e-01, -2.91800827e-01,  5.56609547e-03,\n",
       "          1.18310392e-01,  9.32715982e-02, -1.78334162e-01,\n",
       "         -4.56355885e-03,  1.47591569e-02, -6.68449253e-02,\n",
       "         -1.85690492e-01, -2.56859571e-01,  1.58954352e-01,\n",
       "          1.57894075e-01,  8.47763196e-02,  1.14223927e-01,\n",
       "         -5.71722426e-02, -8.28509107e-02,  1.65018320e-01],\n",
       "        [ 5.13576418e-02, -3.75720859e-02, -1.12655386e-01,\n",
       "          2.84978658e-01,  1.89827513e-02,  1.12006220e-03,\n",
       "          2.10422486e-01, -1.19300701e-01,  3.12764585e-01,\n",
       "         -2.02862695e-01,  2.94238865e-01, -2.22412661e-01,\n",
       "         -1.17022328e-01,  2.01767802e-01, -2.64467634e-02,\n",
       "          1.75464824e-01,  2.44434506e-01,  2.29518846e-01,\n",
       "         -3.11223082e-02,  4.03967220e-04, -2.28255838e-01,\n",
       "         -2.13346466e-01, -1.66607071e-02,  1.06043003e-01,\n",
       "          1.21759571e-01,  3.02573204e-01, -9.07794312e-02,\n",
       "          3.76525581e-01, -2.15607151e-01,  7.41527379e-02],\n",
       "        [-1.78593606e-01, -2.72651166e-01, -1.02183186e-02,\n",
       "          3.08667123e-01,  3.03127557e-01,  9.18486416e-02,\n",
       "          4.42926353e-03, -1.88146070e-01, -2.09451512e-01,\n",
       "          1.16648786e-01,  2.71639436e-01, -2.59939998e-01,\n",
       "          3.06270272e-01, -2.14858785e-01,  1.61242217e-01,\n",
       "         -1.38838127e-01, -1.64723411e-01,  5.62839806e-02,\n",
       "          1.27788663e-01, -2.73015290e-01, -1.58698142e-01,\n",
       "         -1.33412480e-01, -4.62045185e-02,  1.84497550e-01,\n",
       "          1.88359469e-01, -7.29712918e-02, -2.31054589e-01,\n",
       "          8.15515891e-02, -2.78423697e-01,  1.27128482e-01],\n",
       "        [-1.47919208e-01,  1.38331831e-01,  1.03419740e-02,\n",
       "         -8.73839855e-02,  1.57475308e-01,  2.90771157e-01,\n",
       "         -2.78333127e-01,  1.44252107e-02, -7.09996149e-02,\n",
       "         -6.75329641e-02,  3.38981152e-02,  2.01866612e-01,\n",
       "         -7.60906413e-02,  2.05126524e-01, -1.60999373e-01,\n",
       "         -7.68948421e-02,  1.12181518e-03,  2.17341840e-01,\n",
       "         -2.20025569e-01,  2.68874109e-01,  1.10379875e-01,\n",
       "          3.24463487e-01, -1.43507347e-02, -9.13287848e-02,\n",
       "         -8.83515403e-02, -1.62541419e-02,  4.47973348e-02,\n",
       "          2.86754519e-01, -8.27704743e-02,  1.58138186e-01],\n",
       "        [ 1.43566743e-01,  6.08523451e-02,  3.41895610e-01,\n",
       "          1.72602803e-01, -3.43550593e-02,  1.53000981e-01,\n",
       "         -2.08271712e-01, -3.03579628e-01,  2.37130016e-01,\n",
       "          3.27364624e-01,  1.40359895e-02,  7.91948847e-03,\n",
       "          1.94419309e-01, -1.33506879e-01, -1.18322872e-01,\n",
       "         -7.90491104e-02,  7.55312368e-02,  9.20178462e-03,\n",
       "         -3.35236013e-01,  4.94868215e-03,  1.38369054e-01,\n",
       "          7.01527372e-02, -1.55027494e-01, -1.89139724e-01,\n",
       "          1.30188078e-01,  3.75837013e-02, -3.08122784e-01,\n",
       "         -1.31634772e-01, -4.09393478e-03,  2.43702568e-02],\n",
       "        [ 2.73700058e-01, -2.24521384e-01,  1.14460573e-01,\n",
       "         -1.02295943e-01,  9.04118866e-02, -1.11177377e-01,\n",
       "          1.77401751e-01,  3.16920787e-01,  1.57579914e-01,\n",
       "         -2.27171302e-01, -9.73317772e-02,  2.39846408e-01,\n",
       "         -2.91295856e-01, -1.43178537e-01,  2.66103566e-01,\n",
       "          8.23482499e-03,  5.63589344e-03,  6.80003241e-02,\n",
       "          1.00482784e-01, -3.81944478e-02, -1.45620495e-01,\n",
       "         -1.43008664e-01,  2.69037671e-02, -7.33411983e-02,\n",
       "          2.42615148e-01,  3.54879424e-02,  2.62161672e-01,\n",
       "          9.83714312e-02, -2.51277745e-01,  2.33389303e-01],\n",
       "        [-2.60866046e-01,  1.58373509e-02,  2.55554885e-01,\n",
       "          3.48716468e-01, -3.00114304e-01,  1.65244862e-01,\n",
       "         -6.78265616e-02,  2.52738446e-01,  1.31158948e-01,\n",
       "          1.28665954e-01,  1.59751564e-01, -1.85467705e-01,\n",
       "         -2.07394868e-01,  2.00796902e-01, -2.09276676e-01,\n",
       "         -2.72266030e-01, -1.51550025e-01,  3.83631624e-02,\n",
       "          2.83767641e-01, -4.18885648e-02, -2.27307230e-01,\n",
       "          3.24680418e-01,  3.08400542e-01, -1.82075113e-01,\n",
       "          1.64179564e-01,  3.49488288e-01, -2.24533945e-01,\n",
       "         -2.87665874e-01, -3.88345756e-02,  5.74826375e-02],\n",
       "        [ 1.87280215e-02,  2.01673925e-01,  3.13027948e-01,\n",
       "         -1.84104383e-01,  1.39918312e-01,  2.56003022e-01,\n",
       "          1.69800252e-01,  3.14613611e-01, -1.90275729e-01,\n",
       "         -1.61805108e-01,  3.38938355e-01,  2.05803916e-01,\n",
       "         -1.12206258e-01, -2.07536221e-01,  2.16544911e-01,\n",
       "         -7.96022043e-02,  9.09342393e-02, -8.96077305e-02,\n",
       "          5.31850085e-02, -2.78160632e-01, -9.10144150e-02,\n",
       "          5.30560873e-02,  3.80338281e-01,  9.78402570e-02,\n",
       "          3.08896214e-01, -1.41648471e-01,  3.08368146e-01,\n",
       "          3.40252593e-02, -2.88912743e-01, -5.28542623e-02],\n",
       "        [ 2.11227730e-01, -1.00716753e-02, -2.26284370e-01,\n",
       "          6.63188547e-02,  2.14584708e-01,  1.13219731e-01,\n",
       "          1.53139904e-01, -2.49472409e-01,  1.39589101e-01,\n",
       "         -1.68937743e-01,  1.87197402e-01,  1.48251608e-01,\n",
       "          1.86387673e-01, -1.27974510e-01,  4.91587259e-03,\n",
       "          1.84775636e-01, -3.13078374e-01, -1.57823309e-01,\n",
       "         -2.45990828e-01, -6.86925426e-02, -1.15540646e-01,\n",
       "          3.20024192e-01, -2.36422524e-01, -2.93604225e-01,\n",
       "          1.39236346e-01,  1.19949423e-01, -3.09713572e-01,\n",
       "          5.81598133e-02,  8.30262899e-03, -4.74638790e-02],\n",
       "        [ 1.68349028e-01, -5.04244231e-02, -2.17021078e-01,\n",
       "          2.30116889e-01, -4.17120173e-04,  6.80359965e-03,\n",
       "         -1.44955814e-01, -1.95431992e-01,  2.11097166e-01,\n",
       "          2.77464166e-02,  1.63943887e-01,  2.06361011e-01,\n",
       "          2.81906128e-01, -2.52220571e-01,  1.38811618e-01,\n",
       "          1.23867221e-01, -9.12247151e-02, -2.53708422e-01,\n",
       "         -5.90147413e-02, -2.46788055e-01, -1.81733057e-01,\n",
       "          4.50813323e-02,  2.13781640e-01, -3.06241568e-02,\n",
       "          1.95076868e-01,  9.56201404e-02,  2.23105952e-01,\n",
       "          1.66103736e-01, -2.95274138e-01,  5.53747602e-02],\n",
       "        [ 2.05313861e-01, -1.19896226e-01,  5.36783785e-02,\n",
       "         -1.50145860e-02,  2.02416033e-01,  2.85702199e-01,\n",
       "         -6.08394779e-02, -2.34355867e-01,  9.41398218e-02,\n",
       "          3.58117819e-01,  3.51982445e-01, -1.36087120e-01,\n",
       "          1.32716432e-01,  8.90847966e-02,  2.34458789e-01,\n",
       "          1.40970334e-01,  6.23703673e-02, -3.28686535e-01,\n",
       "         -1.90876618e-01,  2.87458330e-01,  4.94816191e-02,\n",
       "         -1.91299349e-01, -1.24277426e-02, -2.53605604e-01,\n",
       "         -1.91746995e-01, -3.23289275e-01,  1.18483491e-01,\n",
       "          9.51118693e-02, -3.15503567e-01, -3.24919194e-01],\n",
       "        [ 1.83425799e-01,  2.38660291e-01,  1.46900177e-01,\n",
       "         -8.28582048e-02, -1.41820654e-01,  1.72834605e-01,\n",
       "          3.51395942e-02, -2.79606134e-01, -1.25303373e-01,\n",
       "         -9.06394497e-02,  2.78268397e-01,  1.25195205e-01,\n",
       "          1.85768351e-01, -3.20702821e-01,  8.80678967e-02,\n",
       "         -2.91630685e-01,  1.29752651e-01,  3.73442888e-01,\n",
       "          1.39931450e-02,  2.74171442e-01,  2.35193092e-02,\n",
       "          3.34253311e-01, -1.10518433e-01,  2.31669933e-01,\n",
       "          1.20798439e-01,  9.04495865e-02, -2.29362383e-01,\n",
       "         -1.43620118e-01,  3.29313844e-01,  8.26927423e-02],\n",
       "        [ 4.07634415e-02,  8.44105557e-02, -8.29941407e-02,\n",
       "         -1.04237981e-01,  6.22933656e-02,  2.21286103e-01,\n",
       "          6.53382242e-02,  1.67104319e-01, -2.52252668e-01,\n",
       "         -5.65481819e-02, -2.23801941e-01, -2.25365713e-01,\n",
       "          6.61794320e-02,  9.33035463e-02,  1.03199422e-01,\n",
       "         -2.31756374e-01, -5.60432933e-02,  1.84154719e-01,\n",
       "          8.96207765e-02,  5.53693958e-02, -2.73970943e-02,\n",
       "          4.04884458e-01,  3.30212340e-02,  2.02752836e-02,\n",
       "          2.67080188e-01,  2.56265283e-01, -2.96431214e-01,\n",
       "          1.40710384e-01,  4.00180548e-01,  2.97666401e-01],\n",
       "        [ 3.34225446e-02,  2.50174344e-01, -3.15600008e-01,\n",
       "          3.37980300e-01, -2.84182638e-01,  8.07315633e-02,\n",
       "         -2.17662051e-01,  2.23228022e-01,  3.65284801e-01,\n",
       "         -1.05286352e-01, -1.44705981e-01, -1.30834654e-01,\n",
       "          1.32951766e-01,  1.29158333e-01, -2.57524878e-01,\n",
       "          1.80765927e-01, -2.07879961e-01, -2.68061578e-01,\n",
       "         -2.21702203e-01, -1.71468168e-01,  3.47740948e-02,\n",
       "          5.95219061e-02,  6.02116715e-03, -2.19401553e-01,\n",
       "          2.79207855e-01, -4.27732691e-02,  2.61018842e-01,\n",
       "          1.45201266e-01, -1.78383231e-01,  6.16761670e-02],\n",
       "        [ 2.95951128e-01, -4.81803566e-02,  2.85429955e-01,\n",
       "         -1.46325201e-01, -1.71217937e-02, -1.44855961e-01,\n",
       "         -2.39381388e-01,  6.69951737e-02,  2.36157641e-01,\n",
       "          1.13256266e-02,  1.79991171e-01,  2.79891968e-01,\n",
       "          2.84228593e-01,  1.46254212e-01,  2.78206676e-01,\n",
       "         -2.75152653e-01,  1.80414200e-01, -2.16679782e-01,\n",
       "          1.76260918e-01,  1.88994884e-01, -3.22720230e-01,\n",
       "         -1.90947875e-01,  5.55888638e-02,  3.13441753e-01,\n",
       "         -1.76038854e-02, -2.56503552e-01, -2.37508431e-01,\n",
       "          1.37900457e-01, -1.09799340e-01, -1.53189018e-01],\n",
       "        [-1.83554024e-01,  1.31487116e-01,  2.59615272e-01,\n",
       "         -1.67550221e-01, -1.17871843e-01, -4.15004008e-02,\n",
       "          2.03295246e-01,  3.06163639e-01,  1.31184757e-01,\n",
       "          3.74975979e-01, -1.73544124e-01,  2.50412643e-01,\n",
       "         -1.12239912e-01,  9.09369886e-02, -7.40765706e-02,\n",
       "         -2.11039990e-01,  9.53871757e-02,  1.69936821e-01,\n",
       "          8.81980807e-02,  1.00190483e-01,  1.67724267e-01,\n",
       "         -2.06475273e-01,  9.83499140e-02, -3.24751765e-01,\n",
       "          4.04137038e-02, -9.19957757e-02, -3.66779454e-02,\n",
       "         -1.60119414e-01,  2.49326602e-01, -6.57674577e-03],\n",
       "        [-2.60322899e-01, -1.40660375e-01,  1.17220558e-01,\n",
       "         -1.78610459e-01, -2.81573180e-02,  1.02705233e-01,\n",
       "         -2.17698619e-01, -5.69406385e-03, -6.55326294e-04,\n",
       "         -3.00899297e-01, -1.47931417e-02,  1.10855609e-01,\n",
       "          5.98950721e-02,  1.18159533e-01,  1.17508925e-01,\n",
       "         -3.77973825e-01,  7.99639225e-02, -2.95915067e-01,\n",
       "         -3.35180432e-01, -9.92423594e-02,  3.15908462e-01,\n",
       "          2.62489635e-03, -9.67901945e-02,  2.38035321e-01,\n",
       "          2.61313207e-02, -1.82204112e-01,  1.08246051e-01,\n",
       "          1.46868555e-02, -1.29289314e-01,  2.26868272e-01]], dtype=float32),\n",
       " array([ 0.02118045,  0.00266128,  0.05489311,  0.01784886,  0.05246897,\n",
       "         0.00667894,  0.02879201,  0.04425374, -0.03238986,  0.01511467,\n",
       "         0.01953233,  0.03264216, -0.00652664, -0.01087157,  0.03875751,\n",
       "         0.00061201,  0.02418623,  0.00879762,  0.0413534 ,  0.04324383,\n",
       "         0.02547554,  0.07385996,  0.05185413, -0.01732945,  0.07263906,\n",
       "         0.04107586,  0.00104173,  0.03597754,  0.05620277,  0.02276164],\n",
       "       dtype=float32)]"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer0.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer1 = model.get_layer(index=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "layer1.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictionsDF = pd.DataFrame(\n",
    "#    data=predictions[1:,1:],    # values\n",
    "#    index=predictions[1:,0],    # 1st column as index\n",
    "#    columns=predictions[0,1:])  # 1st row as the column names\n",
    "\n",
    "predictionsDF = pd.DataFrame(\n",
    "    data=predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictionsDF.to_csv(\"Predictions1.csv\", encoding='utf-8', header=False, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "PredictedLabels = np.ndarray.copy(TrainLabels)\n",
    "PredictedOutcomes = np.ndarray.copy(TrainLabels)\n",
    "for i in range(len(TrainLabels)):\n",
    "  PredictedLabels[i] = np.argmax(predictions[i])\n",
    "  if PredictedLabels[i] == TrainLabels[i]:\n",
    "    PredictedOutcomes[i] = 1\n",
    "  else:\n",
    "    PredictedOutcomes[i] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainDataLabels = np.append(TrainData, TrainLabels, axis=1)\n",
    "TrainDataLabelsPredictions = np.append(TrainDataLabels, PredictedLabels, axis=1)\n",
    "TrainDataLabelsPredictionsOutcomes = np.append(TrainDataLabelsPredictions, PredictedOutcomes, axis=1)\n",
    "TrainDataLabelsPredictionsOutcomesProb = np.append(TrainDataLabelsPredictionsOutcomes, predictions, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "TDLPOP_DF = pd.DataFrame(\n",
    "    data=TrainDataLabelsPredictionsOutcomesProb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TDLPOP_DF.to_csv(\"Predictions2.csv\", encoding='utf-8', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input 0 of layer sequential_6 is incompatible with the layer: expected axis -1 of input shape to have value 28 but received input with shape [None, 3]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-102-6275db2f7208>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#Each ranges from 0 to 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mSingleObservation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.9\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mSinglePrediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSingleObservation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    908\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 909\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    910\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, model, x, batch_size, verbose, steps, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    460\u001b[0m     return self._model_iteration(\n\u001b[1;32m    461\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPREDICT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 462\u001b[0;31m         steps=steps, callbacks=callbacks, **kwargs)\n\u001b[0m\u001b[1;32m    463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36m_model_iteration\u001b[0;34m(self, model, mode, x, y, batch_size, verbose, sample_weight, steps, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    442\u001b[0m               \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m               \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 444\u001b[0;31m               total_epochs=1)\n\u001b[0m\u001b[1;32m    445\u001b[0m           \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    121\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    122\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 86\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_counter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalled_without_tracing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    492\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 494\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    495\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1820\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1821\u001b[0m     \u001b[0;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1822\u001b[0;31m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1823\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1824\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   2148\u001b[0m         \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2149\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mgraph_function\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2150\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2151\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2152\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   2039\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2040\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2041\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   2042\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2043\u001b[0m         \u001b[0;31m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow_core/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    913\u001b[0m                                           converted_func)\n\u001b[1;32m    914\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 358\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mdistributed_function\u001b[0;34m(input_iterator)\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0mstrategy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdistribution_strategy_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     outputs = strategy.experimental_run_v2(\n\u001b[0;32m---> 73\u001b[0;31m         per_replica_function, args=(model, x, y, sample_weights))\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0;31m# Out of PerReplica outputs reduce or pick values to return.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     all_outputs = dist_utils.unwrap_output_dict(\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow_core/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mexperimental_run_v2\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m    758\u001b[0m       fn = autograph.tf_convert(fn, ag_ctx.control_status_ctx(),\n\u001b[1;32m    759\u001b[0m                                 convert_by_default=False)\n\u001b[0;32m--> 760\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extended\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    762\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow_core/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mcall_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   1785\u001b[0m       \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1787\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1788\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1789\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow_core/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36m_call_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   2130\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2131\u001b[0m         replica_id_in_sync_group=constant_op.constant(0, dtypes.int32)):\n\u001b[0;32m-> 2132\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2134\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_reduce_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdestinations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow_core/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    290\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mControlStatusCtx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDISABLED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mismethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36m_predict_on_batch\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    160\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_predict_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mpredict_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_predict_on_batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mpredict_on_batch\u001b[0;34m(model, x)\u001b[0m\n\u001b[1;32m    368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meager_learning_phase_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 370\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    810\u001b[0m         \u001b[0;31m# are casted, not before.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    811\u001b[0m         input_spec.assert_input_compatibility(self.input_spec, inputs,\n\u001b[0;32m--> 812\u001b[0;31m                                               self.name)\n\u001b[0m\u001b[1;32m    813\u001b[0m         \u001b[0mgraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    814\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/input_spec.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    211\u001b[0m                 \u001b[0;34m' incompatible with the layer: expected axis '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m                 \u001b[0;34m' of input shape to have value '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m                 ' but received input with shape ' + str(shape))\n\u001b[0m\u001b[1;32m    214\u001b[0m     \u001b[0;31m# Check shape.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input 0 of layer sequential_6 is incompatible with the layer: expected axis -1 of input shape to have value 28 but received input with shape [None, 3]"
     ]
    }
   ],
   "source": [
    "#CycNorm, DefNorm, CosNorm\n",
    "#Each ranges from 0 to 1\n",
    "SingleObservation = np.array([[0.9, 0.9, 0.9]])\n",
    "SinglePrediction = model.predict(SingleObservation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SinglePrediction[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(SinglePrediction[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(SinglePrediction[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names[np.argmax(SinglePrediction[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BlankLabels = np.array([[0, 0, 0, 0, 0]])\n",
    "\n",
    "i = 0\n",
    "plt.figure(figsize=(6,3))\n",
    "plt.subplot(1,2,1)\n",
    "plot_image(i, SinglePrediction, BlankLabels)\n",
    "plt.subplot(1,2,2)\n",
    "plot_value_array(i, SinglePrediction, BlankLabels)\n",
    "plt.xticks(range(5), class_names, rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
